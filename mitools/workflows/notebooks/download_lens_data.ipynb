{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from mitools.nlp import LENS_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1358dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LENS_URL = 'https://api.lens.org/scholarly/search'\n",
    "N_PAPERS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_string(query_str, amount=1000, start_value=0):\n",
    "    return f'''{{\n",
    "    \"query\": {{\n",
    "        \"bool\":{{\n",
    "            \"must\": [\n",
    "                {{\"match\": {{\"publication_type\": \"journal article\"}}}},\n",
    "                {{\"match\": {{\"has_abstract\": true}}}},\n",
    "                {{\"match\": {{\"is_open_access\": true}}}},\n",
    "                {{\"query_string\": {{\n",
    "                        \"query\": \"{query_str}\",\n",
    "                        \"fields\": [\n",
    "                            \"title\",\n",
    "                            \"abstract\",\n",
    "                            \"full_text\"\n",
    "                        ],\n",
    "                        \"default_operator\": \"and\"\n",
    "                    }}\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "    }},\n",
    "    \"sort\": [\n",
    "    {{\"scholarly_citation_count\": \"desc\"}},\n",
    "    {{\"relevance\": \"desc\"}}\n",
    "    ],\n",
    "    \"from\": {start_value},\n",
    "    \"size\":{amount}\n",
    "}}'''\n",
    "\n",
    "def do_request(query_str, start_value=0):\n",
    "    request_data = create_query_string(query_str, start_value=start_value)\n",
    "    headers = {'Authorization': LENS_API_KEY, 'Content-Type': 'application/json'}\n",
    "    response = requests.post(LENS_URL, data=request_data, headers=headers)\n",
    "    if response.status_code != requests.codes.ok:\n",
    "        print(response.status_code)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a314a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_words = [\n",
    "    'Urban',\n",
    "    'City',\n",
    "]\n",
    "\n",
    "sub_words = [\n",
    "    'Lockdown',\n",
    "    'Covid',\n",
    "    'Resilience',\n",
    "    'Research',\n",
    "    'Adaptation',\n",
    "    'Policy',\n",
    "    'Planning',\n",
    "    'Building',\n",
    "    'Wind',\n",
    "    'Simulation',\n",
    "    'Quality',\n",
    "    'Land',\n",
    "    'Emission',\n",
    "    'Climate',\n",
    "    'Risk',\n",
    "    'Carbon',\n",
    "    'Energy',\n",
    "    'Temperature',\n",
    "    'Model',\n",
    "    'Data',\n",
    "    'Air',\n",
    "    'Space',\n",
    "    'Spatial',\n",
    "    'Surface',\n",
    "    'Thermal',\n",
    "    'Heat',\n",
    "    'Comfort',\n",
    "    'Effect',\n",
    "]\n",
    "\n",
    "query_strs = [f\"{main_w} {sub_w}\" for main_w in main_words for sub_w in sub_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_cols = {\n",
    "    'Lens ID': 'lens_id', \n",
    "    'Title': 'title', \n",
    "    'Date Published': 'date_published', \n",
    "    'Publication Year': 'year_published',\n",
    "    'Publication Type': 'publication_type', \n",
    "    'Source Title': 'source_title', \n",
    "    'ISSNs': 'issns', \n",
    "    'Publisher': 'publisher',\n",
    "    'Source Country': 'source_country', \n",
    "    'Author/s': 'authors', \n",
    "    'Abstract': 'abstract', \n",
    "    'Volume': 'volume', \n",
    "    'Issue Number': None,\n",
    "    'Start Page': 'start_page', \n",
    "    'End Page': 'end_page', \n",
    "    'Fields of Study': 'fields_of_study', \n",
    "    'Keywords': 'keywords', \n",
    "    'MeSH Terms': 'mesh_terms',\n",
    "    'Chemicals': None, \n",
    "    'Funding': None, \n",
    "    'Source URLs': 'source_urls',\n",
    "    'External URL': None,\n",
    "    'PMID': 'pmid',\n",
    "    'DOI': 'doi',\n",
    "    'Microsoft Academic ID': 'magid',\n",
    "    'PMCID': 'pmcid',\n",
    "    'Citing Patents Count': None,\n",
    "    'References': 'references',\n",
    "    'References Count': 'references_count',\n",
    "    'Citing Works Count': 'scholarly_citations_count',\n",
    "    'Is Open Access': 'isopen_access',\n",
    "    'Open Access License': None,\n",
    "    'Open Access Colour': 'open_access'\n",
    "}\n",
    "\n",
    "inv_articles_cols = {v: k for k, v in articles_cols.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ac14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_external_ids(x, col):\n",
    "    for val in x:\n",
    "        if val['type'] == col:\n",
    "            return val['value']\n",
    "    return ''\n",
    "\n",
    "def extract_source_data(x, col):\n",
    "    if col != 'issns':\n",
    "        if col in x:\n",
    "            return x[col]\n",
    "    else:\n",
    "        if 'issn' in x:\n",
    "            return x['issn'][0]['value']\n",
    "    return ''\n",
    "\n",
    "def extract_author_names(x):\n",
    "    authors = []\n",
    "    for a in x:\n",
    "        author = f\"{a['first_name']}\" if 'first_name' in a else ''\n",
    "        author += \" \" if 'last_name' in a and 'last_name' in a else ''\n",
    "        author += f\"{a['last_name']}\" if 'last_name' in a else ''\n",
    "        authors.append(author)\n",
    "    return ', '.join(authors)\n",
    "\n",
    "def extract_open_acess_colour(x):\n",
    "    if 'colour' in x:\n",
    "        return x['colour']\n",
    "    return ''\n",
    "import numpy as np\n",
    "def extract_date_published_parts(x):\n",
    "    year = x[0] if len(x) > 0 else 0\n",
    "    month = x[1] if len(x) > 1 else 1\n",
    "    day = x[2] if len(x) > 2 else 1\n",
    "    return pd.Timestamp(year=year, month=month, day=day)\n",
    "\n",
    "def response_to_df(response: dict):\n",
    "    df = pd.DataFrame([response])\n",
    "    \n",
    "    if 'date_published' in df:\n",
    "        df['date_published'] = pd.to_datetime(df['date_published'])\n",
    "    elif 'date_published_parts' in df:\n",
    "        df['date_published'] = df['date_published_parts'].apply(extract_date_published_parts)\n",
    "    else:\n",
    "        df['date_published'] = ''\n",
    "    \n",
    "    id_cols = ['pmcid', 'magid', 'doi', 'pmid']\n",
    "    for col in id_cols:\n",
    "        df[col] = df['external_ids'].apply(lambda x: extract_external_ids(x, col))\n",
    "        \n",
    "    source_cols = ['source_title', 'source_country', 'issns', 'publisher', 'publication_type']\n",
    "    for col in source_cols:\n",
    "        df[col] = df['source'].apply(lambda x: extract_source_data(x, col))\n",
    "        \n",
    "    df['authors'] = df['authors'].apply(extract_author_names) if 'authors' in df else ''\n",
    "    \n",
    "    df['fields_of_study'] = df['fields_of_study'].apply(lambda x: ', '.join(x))  if 'fields_of_study' in df else ''\n",
    "    df['keywords'] = df['keywords'].apply(lambda x: ', '.join(x)) if 'keywords' in df else ''\n",
    "    df['languages'] = df['languages'].apply(lambda x: ', '.join(x))\n",
    "    df['open_access'] = df['open_access'].apply(extract_open_acess_colour)\n",
    "    df = df.rename(columns=inv_articles_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab436afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_str in query_strs:\n",
    "    csv = f\"./{query_str.lower().replace(' ', '_')}_lens_articles.csv\"\n",
    "    if not os.path.exists(csv):\n",
    "        start_value = 0\n",
    "        response = do_request(query_str)\n",
    "        total_papers = response.json()[\"total\"]\n",
    "        print(f'For {query_str} there is {total_papers} results')\n",
    "        papers = response.json()['data']\n",
    "        retrieved_papers = len(papers)\n",
    "        while retrieved_papers < min(N_PAPERS, total_papers):\n",
    "            print(f\"{retrieved_papers}/{min(N_PAPERS, total_papers)}\")\n",
    "            response = do_request(query_str, start_value=retrieved_papers)\n",
    "            papers.extend(response.json()['data'])\n",
    "            retrieved_papers = len(papers)\n",
    "        df = pd.concat([response_to_df(paper) for paper in papers], axis=0).reset_index(drop=True)\n",
    "        df.to_csv(csv)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48681019",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tools",
   "language": "python",
   "name": "tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
